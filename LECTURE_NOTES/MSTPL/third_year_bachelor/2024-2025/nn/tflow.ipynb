{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOTA: STUDIARE -> [DISCESA DEL GRADIENTE E FUNZIONI DI ATTIVAZIONE (MODELLI E CARATTERISTICHE)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import librosa as lb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pm/AcaHub/CoursesHub/LECTURE_NOTES/MSTPL/third_year_bachelor/2024-2025/nn'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"/Users/pm/AcaHub/CoursesHub/LECTURE_NOTES/MSTPL/third_year_bachelor/2024-2025/nn/NeuralNetwork_genreClassification/test_ridotto\"\n",
    "SR = 22050\n",
    "SAMPLES = 30 * SR\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_h5_dataset(dataset_name: str, n_mfcc: int = 13, n_fft: int = 2048, hop: int = 512, n_segment: int = 5) -> None:\n",
    "    sample_seg = int(SAMPLES / n_segment)\n",
    "    mfcc_vectors = int(sample_seg / hop) + 1\n",
    "    \n",
    "    with h5py.File(dataset_name, \"w\") as hfile:\n",
    "        generi = []\n",
    "        mfccs = []\n",
    "        target = []\n",
    "        for i, (root, _, files) in enumerate(os.walk(PATH)):\n",
    "            if root is not PATH:\n",
    "                g = root.split(\"/\")\n",
    "                generi.append(g[-1])\n",
    "                for f in files:\n",
    "                    if f.endswith(\".wav\"):\n",
    "                        print(f\"Sto processando: {f}\")\n",
    "                        pfile = os.path.join(root, f)\n",
    "                        frame, _ = lb.load(pfile, sr=SR)\n",
    "                        \n",
    "                        for n in range(n_segment):\n",
    "                            s = sample_seg * n\n",
    "                            e = s + sample_seg\n",
    "                            frame_segment = frame[s:e]\n",
    "                            mfcc = lb.feature.mfcc(y=frame_segment, n_mfcc=n_mfcc, hop_length=hop, n_fft=n_fft, sr=SR)\n",
    "                            mfcc = mfcc.T\n",
    "                            \n",
    "                            if len(mfcc) == mfcc_vectors:\n",
    "                                mfccs.append(mfcc)\n",
    "                                target.append(i - 1)\n",
    "            \n",
    "        _ = hfile.create_dataset(name=\"mfccs\", data=np.array(mfccs))                       \n",
    "        hfile.attrs[\"generi\"] = generi\n",
    "        hfile.attrs[\"target\"] = target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sto processando: pop.00000.wav\n",
      "Sto processando: pop.00001.wav\n",
      "Sto processando: metal.00000.wav\n",
      "Sto processando: metal.00001.wav\n",
      "Sto processando: disco.00001.wav\n",
      "Sto processando: disco.00000.wav\n",
      "Sto processando: blues.00000.wav\n",
      "Sto processando: blues.00001.wav\n",
      "Sto processando: reggae.00001.wav\n",
      "Sto processando: reggae.00000.wav\n",
      "Sto processando: classical.00001.wav\n",
      "Sto processando: classical.00000.wav\n",
      "Sto processando: rock.00000.wav\n",
      "Sto processando: rock.00001.wav\n",
      "Sto processando: hiphop.00000.wav\n",
      "Sto processando: hiphop.00001.wav\n",
      "Sto processando: country.00000.wav\n",
      "Sto processando: country.00001.wav\n",
      "Sto processando: jazz.00001.wav\n",
      "Sto processando: jazz.00000.wav\n"
     ]
    }
   ],
   "source": [
    "create_h5_dataset(dataset_name=\"generi_test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-195.25616  ,   75.588264 ,   48.67987  , ...,    9.667136 ,\n",
       "           4.716035 ,    5.696352 ],\n",
       "       [-150.96812  ,   41.620117 ,   59.39933  , ...,    7.1447954,\n",
       "          -3.0786247,    2.570571 ],\n",
       "       [-132.99374  ,   39.527184 ,   64.94699  , ...,   11.40547  ,\n",
       "          -3.0165803,   -6.975159 ],\n",
       "       ...,\n",
       "       [ -82.491684 ,   -2.231089 ,   35.151276 , ...,    5.2966957,\n",
       "          -1.7098525,   -3.078438 ],\n",
       "       [ -88.030464 ,    7.328567 ,   49.474648 , ...,    0.670177 ,\n",
       "          -1.3818641,   -0.5476265],\n",
       "       [ -96.2717   ,   17.768566 ,   50.19065  , ...,   -5.4913235,\n",
       "          -0.5770228,    1.4640749]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = h5py.File(\"generi_test.h5\", \"r\")\n",
    "data[\"mfccs\"][0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
